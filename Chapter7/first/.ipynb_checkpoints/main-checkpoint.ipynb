{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 需要实现四个函数  train、val、test、help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/first\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "from config import opt\n",
    "from visualize import Visualizer\n",
    "from torchvision import transforms as T\n",
    "import torchvision as tv\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader\n",
    "from model import NetG, NetD\n",
    "from torch.autograd import Variable\n",
    "from torchnet import meter\n",
    "import tqdm\n",
    "import os\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    # step1: configure\n",
    "    opt.parse(**kwargs)\n",
    "    if opt.vis:\n",
    "        vis = Visualizer(opt.env)\n",
    "    # step2: data\n",
    "    normalize = T.Normalize(mean = [0.5,0.5,0.5], std = [0.5,0.5,0.5] )\n",
    "    transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize(opt.image_size),\n",
    "        T.CenterCrop(opt.image_size),\n",
    "        T.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "    # 对于这个模型 transform对于train和test没有区别\n",
    "    dataset = tv.datasets.ImageFolder(opt.data_path,transform=transforms)\n",
    "    dataloader = DataLoader(dataset,\n",
    "                            batch_size = opt.batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=opt.num_workers,\n",
    "                            drop_last=True)\n",
    "    \n",
    "    true_labels = Variable(t.ones(opt.batch_size))\n",
    "    false_labels = Variable(t.zeros(opt.batch_size))\n",
    "    fix_noises = Variable(t.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "    noises = Variable(t.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "    \n",
    "    # step3: model\n",
    "    netg, netd = NetG(opt), NetD(opt)\n",
    "    map_location = lambda storage, loc:storage\n",
    "    if opt.netg_path:\n",
    "        netg.load_state_dict(t.load(opt.netg_path), map_location = map_location)\n",
    "    if opt.netd_path:\n",
    "        netd.load_state_dict(t.load(opt.netd_path), map_location = map_location)\n",
    "        \n",
    "    # step4: criterion and optimizer\n",
    "    optimizer_g = t.optim.Adam(params=netg.parameters(), lr = opt.lrg, betas=(opt.beta1,0.999))\n",
    "    optimizer_d = t.optim.Adam(params=netd.parameters(), lr = opt.lrd, betas=(opt.beta1,0.999))\n",
    "    criterion = t.nn.BCELoss()\n",
    "    \n",
    "    # step: meters\n",
    "    errord_meter = meter.AverageValueMeter()\n",
    "    errorg_meter = meter.AverageValueMeter()\n",
    "    \n",
    "    if opt.use_gpu:\n",
    "        netd.cuda()\n",
    "        netg.cuda()\n",
    "        criterion.cuda()\n",
    "        true_labels, fake_labels = true_labels.cuda(), fake_labels.cuda()\n",
    "        fix_noises, noises = fix_noises.cuda(), noises.cuda()\n",
    "    \n",
    "    # step5: train\n",
    "    for epoch in range(opt.max_epoch):\n",
    "        ## 5.1 train\n",
    "        for ii,(data, _) in tqdm.tqdm(enumerate(dataloader)):\n",
    "            real_img = Variable(data)\n",
    "            if opt.use_gpu:\n",
    "                real_img = real_img.cuda()\n",
    "            if (ii+1) % opt.d_every ==0:\n",
    "                # 判别器\n",
    "                optimizer_d.zero_grad()\n",
    "                # 真图片\n",
    "                output = netd(real_img)\n",
    "                error_d_real = criterion(output, true_labels)\n",
    "                error_d_real.backward()\n",
    "                # 假图片\n",
    "                noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "                fake_img =  netg(noises).detach()\n",
    "                fake_output = netd(fake_img)\n",
    "                error_d_fake = criterion(fake_output, fake_labels)\n",
    "                error_d_fake.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                error_d = error_d_real+error_d_fake\n",
    "                errord_meter.add(error_d.data)\n",
    "                \n",
    "            if (ii+1) % opt.g_every == 0:\n",
    "                optimizer_g.zero_grad()\n",
    "                noises.data.copy_(t.randn(opt.batch_size, opt.nz, 1, 1))\n",
    "                fake_img = netg(noises)\n",
    "                output = netd(fake_img)\n",
    "                error_g = criterion(output, true_labels)\n",
    "                error_g.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                errorg_meter.add(error_g.data)\n",
    "                \n",
    "            ## 5.2 validate and visualize\n",
    "            if (ii+1) % opt.print_freq == 0 and opt.vis:\n",
    "                if os.path.exists(opt.debug_file):\n",
    "                    import ipdb\n",
    "                    ipdb.set_trace()\n",
    "                fix_fake_imgs = netg(fix_noises) # batch_size*nz*1*1 --> batch_size(256)*3*96*96 \n",
    "                vis.images(fix_fake_imgs.data.cpu().numpy()[:64]*0.5+0.5, win = 'fix_fake')\n",
    "                vis.images(real_img.data.cpu().numpy()[:64]*0.5+0.5, win = 'real')\n",
    "                vis.plot(win = 'errord',y= errord_meter.value()[0])\n",
    "                vis.plot(win = 'errorg',y= errorg_meter.value()[0])\n",
    "                \n",
    "            \n",
    "        ## 5.3 save model\n",
    "        if (epoch+1)%opt.save_freq == 0:\n",
    "            t.save(netd.state_dict(), 'checkpoints/netd_%s.pth' % epoch)\n",
    "            t.save(netg.state_dict(), 'checkpoints/netg_%s.pth' % epoch)\n",
    "            # tv.utils.save_image和tv.utils.make_grid基本是一个东西，输入是tensor,[batch, fear,H,W],0-1的范围，可以看成是ToTensor()后的结果\n",
    "            tv.utils.save_image(fix_fake_imgs.data[:64],'%s/%s.png' % (opt.save_path, epoch),normalize=True, range=(-1,1))\n",
    "            #?????? 因为数据集少，所以为了避免每次重置的噪声，多几个epoch再重置，等下试试每次重置的话这个误差的变化情况\n",
    "            errord_meter.reset()\n",
    "            errorg_meter.reset()\n",
    "            optimizer_g = t.optim.Adam(params=netg.parameters(), lr = opt.lrg, betas=(opt.beta1,0.999))\n",
    "            optimizer_d = t.optim.Adam(params=netd.parameters(), lr = opt.lrd, betas=(opt.beta1,0.999)) \n",
    "            # ?????\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## 5.4 update learning rate\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_noises = Variable(t.randn(256, 100, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = './checkpoints/netg_199.pth'\n",
    "netg = NetG(opt)\n",
    "netg.load_state_dict(t.load(path, map_location = lambda sto,loc:sto))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_fake_img = netg(fix_noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv.utils.save_image(fix_fake_img.data[:64],'1.png' ,normalize=True, range=(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fix_fake_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-904e57dec896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfix_fake_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1.png'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fix_fake_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "tv.utils.save_image(fix_fake_imgs.data[:64],'2.png' ,normalize=False, range=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, dataloader):\n",
    "    # 验证在固定噪声上生成的图片的正确率。\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(**kwargs):\n",
    "    # 在这里，更名为generate\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help():\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(**kwargs):\n",
    "    opt.parse(**kwargs)\n",
    "    netg, netd = NetG(opt).eval(), NetD(opt).eval()\n",
    "    noises = t.randn(opt.gen_search_num, opt.nz, 1, 1).normal_(opt.gen_mean, opt.gen_std)\n",
    "    \n",
    "    if opt.netd_path:\n",
    "        netd.load_state_dict(t.load(opt.netd_path,map_location=lambda storage, loc:storage))\n",
    "    if opt.netg_path:\n",
    "        netg.load_state_dict(t.load(opt.netg_path,map_location=lambda storage, loc:storage))\n",
    "    \n",
    "    if opt.use_gpu:\n",
    "        netd.cuda()\n",
    "        netg.cuda()\n",
    "        noises = noises.cuda()\n",
    "    # 生成图片，并计算图片在判别器的分数\n",
    "    fake_img = netg(noises)\n",
    "    scores = netd(fake_img).data\n",
    "    # 选好的\n",
    "    index = scores.topk(opt.gen_num)[1]\n",
    "    result = []\n",
    "    for ii in index:\n",
    "        # tensor的截取与合并  cat, stack,cat+view=stack,stack 新增维度进行合并\n",
    "        result.append(fake_img.data[ii])\n",
    "    tv.utils.save_image(t.stack(result), opt.gen_img, normalize=True, range=(-1,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetG(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(4, 4), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(4, 4), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netg = NetG(opt)\n",
    "netg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_location(storage,loc):\n",
    "    # print(storage)\n",
    "    print('_________1_______')\n",
    "    print(loc)\n",
    "    return storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__func__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__self__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(netg.state_dict,'checkpoints/netg.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = t.load('checkpoints/netg.pth',map_location=lambda storage, loc:storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n",
      "_________1_______\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "tmp = t.load('checkpoints/netg.pth',map_location=map_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of NetG(\n",
       "  (main): Sequential(\n",
       "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(4, 4), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace)\n",
       "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(4, 4), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
       "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace)\n",
       "    (12): ConvTranspose2d(64, 3, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1), bias=False)\n",
       "    (13): Tanh()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'is_cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-acc52b8c19dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'is_cuda'"
     ]
    }
   ],
   "source": [
    "tmp.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = t.Tensor(3,4)\n",
    "tensor_cuda = tensor.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_cuda.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
