{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7db98ca8027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "from config import opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchnet import meter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    # step: configure\n",
    "    opt._parse(**kwargs)\n",
    "    device = t.device('cuda') if opt.use_gpu else t.device('cpu')\n",
    "    if opt.env:\n",
    "        vis = Visualizer(env=opt.env)\n",
    "    # step: data\n",
    "    data, word2ix, ix2word = get_data(opt) # data numpy二维数组， word2ix, ix2word 字典\n",
    "    # from_numpy共享内存，一个数字的变化也会影响另一个，但是t.tensor不会共享内存，两个基本完全独立\n",
    "    data = t.from_numpy(data)\n",
    "    # 这里是因为鸭子类型，还需要考虑考虑\n",
    "    dataloader = DataLoader(data, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "    \n",
    "    # step: model && criterion && meter && optimizer \n",
    "    model = PoetryModel(len(word2ix), opt.embedding_dim, opt.hidden_dim, opt.num_layers)\n",
    "    if opt.model_path:\n",
    "        model.load_state_dict(t.load(opt.model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = t.optim.Adam(model.parameters(), lr=opt.lr)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "    \n",
    "    \n",
    "    # step: train\n",
    "    for epoch in range(opt.epoch):\n",
    "        loss.reset()\n",
    "        for ii, x in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            # embedding层的输入必须是LongTensor型\n",
    "            # 现在x是tensor (batchsize*seq_len)，LSTM的输入需要是(seq_len, batch_size, embedding_dim)\n",
    "            # 矩阵的转置会导致存储空间不连续， 需要调用.contiguous()方法使其连续\n",
    "            x = x.long().transpose(1,0).contiguous()\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            input, target = x[:-1,:], x[1:,:]  # target :(seq_len, batch_size)\n",
    "            # 运行的时候这里要看一下大小\n",
    "            output,_ = model(input)  # output size (seq_len*batch_size, vocab_size)\n",
    "            loss = criterion(output, target.view(-1)) # 交叉熵损失的定义\n",
    "            # 这里需要重新想明白，这个lstm是怎么个输入输出\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 这里的loss是一个只有一个数字的tensor,\n",
    "            # loss.item()返回一个新的Python的对应的类型，不共享内存，改变不会影响彼此\n",
    "            # 经师兄提醒，才注意到计算评价loss的时候，需要想办法去除掉loss.backward等特性，避免时间长了占内存，\n",
    "            # 这里没有loss.data，loss.data也会有backward等特性，还是属于tensor系列，突然感觉自己还是遗漏了好多点。\n",
    "            # 现在只能一边做，一边查缺补漏，看到哪里，学到哪里，对于一些细节要经常去查。\n",
    "            # 这里需要重新解释一下，每一个tensor代表一个计算图，如果直接使用tensor进行累加的话，会造total_loss的计算图不断累加的\n",
    "            # 有点乱了，我去，不管了，先记住，对于损失累加，我们只使用loss.item,这是种完全截断计算图的方法\n",
    "            loss_meter.add(loss.item())\n",
    "            # step: visualize and validate\n",
    "            if (ii+1)%opt.print_freq == 0 and opt.env:\n",
    "                if os.path.exits(opt.debug_file):\n",
    "                    ipdb.set_trace()\n",
    "                \n",
    "                vis.plot('loss',loss_meter.value()[0])\n",
    "                # 诗歌原文\n",
    "                # x tensor size (seq_len, batch_size）\n",
    "                # 二重列表生成式, poetrys:[['我''你'],[]]\n",
    "                poetries = [[ix2word(word_) for word_ in x[:,j_]] for j_ in range(x.shape[1])]\n",
    "                vix.text( '<br/>'.join([''.join(poetry) for poetry in poetries]), win = u'origin_poem'  )\n",
    "                \n",
    "                # 生成的诗歌\n",
    "                gen_poetris = []\n",
    "                # 分别以这几个字作为诗歌的第一个字，生成8首诗 验证模型\n",
    "                for word in list(u'春江花月夜凉如水'):\n",
    "                    gen_poetry = \n",
    "                \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, start_words, ix2word, word2ix, prefix_words=None):\n",
    "    \"\"\"\n",
    "    给定一段词，，根据这几个字接着生成一首完整的诗歌\n",
    "    @model: 模型\n",
    "    @start_words: u'春江潮水连海平'\n",
    "    \n",
    "    \"\"\"\n",
    "    # 第一个输入的字，模型输入 size (seq_len, batch_size)\n",
    "    input = t.Tensor([word2ix['<start>']]).view(1,1).long()\n",
    "    device = t.device('cuda') if opt.use_gpu else t.device('cpu')\n",
    "    input.to(device)\n",
    "    \n",
    "    # 暂时不知道这个prefix_words的用法\n",
    "    # 这里应该是为了保留hidden，\n",
    "    if prefix_words:\n",
    "        for word in prefix_words:\n",
    "            output, hidden = model(input, hidden)\n",
    "            input = input.data.new.([word2ix[word]]).view(1,1)\n",
    "            \n",
    "    # 这一段的逻辑是什么？？？ \n",
    "    # 每次取给定的字作为输入，求hidden和output，对于output，每次取概率最大的\n",
    "    results = list(start_words)\n",
    "    start_word_len = len(start_words)\n",
    "    for i in range(opt.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        \n",
    "        if i < start_word_len:\n",
    "            w = results[i]\n",
    "            input = input.data.new.([word2ix[w]]).view(1,1)\n",
    "        else:\n",
    "            # output size 1×vocab_size [[1,2,3,...]]\n",
    "            # 这里应该看一下，输出output是个什么东西\n",
    "            top_index = output.data[0].topk(1)[1][0].item()\n",
    "            w = ix2word(top_index)\n",
    "            results.append(w)\n",
    "            input = input.data.new.([word2ix[w]]).view(1,1)\n",
    "        if w == '<EOP>':\n",
    "            del results[-1]\n",
    "            break\n",
    "            \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.arange(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.topk(x,1)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = 2*a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.var>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x7f61e54dbfd0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.data.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = aa.new([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.data.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.data.new([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.data??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1], dtype=torch.uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a==a.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.4381e+02,  4.5696e-41, -5.5925e+12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.Tensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.Tensor([3,6])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tensor(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.tensor([3,5])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.Tensor??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
