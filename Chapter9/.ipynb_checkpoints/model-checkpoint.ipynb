{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding需要重新看看说明，是一个什么样的原理\n",
    "\n",
    "LSTM的理解：(https://www.zybuluo.com/hanbingtao/note/581764)\n",
    "\n",
    "LSTM的理解：colah.github.io\n",
    "\n",
    "晚上去找了同学，才知道了一点关于LSTM的编码器和解码器，不过对于loss的定义还是不清晰，这里还是等写完main函数再看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2, 30])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "m = nn.Linear(20,30)\n",
    "m.bias.shape\n",
    "input = torch.randn(1,3,2,20)\n",
    "input.shape\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        \"\"\"\n",
    "        @vocab_size: int 表示输入字的个数\n",
    "        @embedding_dim: int 表示希望这些字可以被多少维的向量表示\n",
    "        这两个参数的用法  nn.Embedding(vocab_size, embedding_dim)\n",
    "        @hidden_dim:  int 是LSTM的隐藏单元的维度\n",
    "        @return: \n",
    "        \"\"\"\n",
    "        super(PoetryModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # 这个lstm的定义有疑问\n",
    "        self.lstm = nn.LSTM(embedding_dim, self.hidden_dim, num_layers)\n",
    "        # Linear层还有异议，需要重新看一下定义\n",
    "        self.linear1 = nn.Linear(self.hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        \"\"\"\n",
    "        @input: tensor, (seq_len, batch_size)  \n",
    "        @hidden: tuple,(tensor, tensor)\n",
    "        \"\"\"\n",
    "        seq_len, batch_size = input.size()\n",
    "        \n",
    "        if hidden is None:\n",
    "            # 这里的new方法存疑\n",
    "            # view()和reshape的功能差不多，前者只能是连续内存，后者都行， \n",
    "            # view_as(t.tensor(4,3))\n",
    "            h_0 = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "            c_0 = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "        else:\n",
    "            h_0, c_0 = hidden\n",
    "        \n",
    "        embeds = self.embeddings(input) # embeds size: (seq_len, batch_size, embeding_dim)\n",
    "        output, hidden = self.lstm(embeds, (h_0, c_)) \n",
    "        # output size (seq_len, batch_size, hidden_dim)\n",
    "        # hidden tuple,每一个元素的维度 (num_layers, batch_size, hidden_dim)\n",
    "        # 这里感觉上下两个维都对不上啊，感觉\n",
    "        # 这里维度能对应上了， Linear层的输入是(batch_size,*,in_features) 输出是（batch_size, *, out_features)\n",
    "        output = self.linear1(output.view(-1, self.hidden_dim))\n",
    "        # output size (seq_len*batch_size, vocab_size)\n",
    "        return output, hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Tensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  4.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.data.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.data.new([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.Tensor(range(8)).reshape(2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.reshape(1,1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.,  2.,  2.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.data.new((2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[0]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 100.,  100.,  100.,  100.,  100.,  100.,  100.,  100.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 100.,  100.],\n",
       "         [ 100.,  100.]],\n",
       "\n",
       "        [[ 100.,  100.],\n",
       "         [ 100.,  100.]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = b.view(1,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 100.,  100.,  100.,  100.],\n",
       "         [ 100.,  100.,  100.,  100.]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0]=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1000.,  1000.,  1000.,  1000.],\n",
       "         [ 1000.,  1000.,  1000.,  1000.]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1000.,  1000.],\n",
       "         [ 1000.,  1000.]],\n",
       "\n",
       "        [[ 1000.,  1000.],\n",
       "         [ 1000.,  1000.]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1000.,  1000.,  1000.,  1000.,  1000.,  1000.,  1000.,\n",
       "           1000.]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
