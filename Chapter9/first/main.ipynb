{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7db98ca8027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'"
     ]
    }
   ],
   "source": [
    "from config import opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train()----generate()\n",
    "gen()----generate()\n",
    "    |----gen_acrostic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchnet import meter\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(**kwargs):\n",
    "    # step: configure\n",
    "    opt._parse(**kwargs)\n",
    "    device = t.device('cuda') if opt.use_gpu else t.device('cpu')\n",
    "    if opt.env:\n",
    "        vis = Visualizer(env=opt.env)\n",
    "    # step: data\n",
    "    data, word2ix, ix2word = get_data(opt) # data numpy二维数组， word2ix, ix2word 字典\n",
    "    # from_numpy共享内存，一个数字的变化也会影响另一个，但是t.tensor不会共享内存，两个基本完全独立\n",
    "    data = t.from_numpy(data)\n",
    "    # 这里是因为鸭子类型，还需要考虑考虑\n",
    "    dataloader = DataLoader(data, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "    \n",
    "    # step: model && criterion && meter && optimizer \n",
    "    model = PoetryModel(len(word2ix), opt.embedding_dim, opt.hidden_dim, opt.num_layers)\n",
    "    if opt.model_path:\n",
    "        model.load_state_dict(t.load(opt.model_path))\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = t.optim.Adam(model.parameters(), lr=opt.lr)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "    \n",
    "    \n",
    "    # step: train\n",
    "    for epoch in range(opt.epoch):\n",
    "        loss.reset()\n",
    "        for ii, x in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            # embedding层的输入必须是LongTensor型\n",
    "            # 现在x是tensor (batchsize*seq_len)，LSTM的输入需要是(seq_len, batch_size, embedding_dim)\n",
    "            # 矩阵的转置会导致存储空间不连续， 需要调用.contiguous()方法使其连续\n",
    "            x = x.long().transpose(1,0).contiguous()\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            input, target = x[:-1,:], x[1:,:]  # target :(seq_len, batch_size)\n",
    "            # 运行的时候这里要看一下大小\n",
    "            output,_ = model(input)  # output size (seq_len*batch_size, vocab_size)\n",
    "            loss = criterion(output, target.view(-1)) # 交叉熵损失的定义\n",
    "            # 这里需要重新想明白，这个lstm是怎么个输入输出\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 这里的loss是一个只有一个数字的tensor,\n",
    "            # loss.item()返回一个新的Python的对应的类型，不共享内存，改变不会影响彼此\n",
    "            # 经师兄提醒，才注意到计算评价loss的时候，需要想办法去除掉loss.backward等特性，避免时间长了占内存，\n",
    "            # 这里没有loss.data，loss.data也会有backward等特性，还是属于tensor系列，突然感觉自己还是遗漏了好多点。\n",
    "            # 现在只能一边做，一边查缺补漏，看到哪里，学到哪里，对于一些细节要经常去查。\n",
    "            # 这里需要重新解释一下，每一个tensor代表一个计算图，如果直接使用tensor进行累加的话，会造total_loss的计算图不断累加的\n",
    "            # 有点乱了，我去，不管了，先记住，对于损失累加，我们只使用loss.item,这是种完全截断计算图的方法\n",
    "            loss_meter.add(loss.item())\n",
    "            # step: visualize and validate\n",
    "            if (ii+1)%opt.print_freq == 0 and opt.env:\n",
    "                if os.path.exits(opt.debug_file):\n",
    "                    ipdb.set_trace()\n",
    "                \n",
    "                vis.plot('loss',loss_meter.value()[0])\n",
    "                # 诗歌原文\n",
    "                # x tensor size (seq_len, batch_size）\n",
    "                # 二重列表生成式, poetrys:[['我''你'],[..]]\n",
    "                poetries = [[ix2word(word_) for word_ in x[:,j_]] for j_ in range(x.shape[1])]\n",
    "                vix.text( '<br/>'.join([''.join(poetry) for poetry in poetries]), win = u'origin_poem'  )\n",
    "                \n",
    "                # 生成的诗歌\n",
    "                gen_poetris = []\n",
    "                # 分别以这几个字作为诗歌的第一个字，生成8首诗 验证模型\n",
    "                # gen_poetris 二重list，每一个list都是一首诗 [['我','你'],[]]\n",
    "                for word in list(u'春江花月夜凉如水'):\n",
    "                    gen_poetry = generate(model, word, ix2word, word2ix)\n",
    "                    gen_poetris.append(gen_poetry)\n",
    "                # gen_poetris 二重列表，与poetries一致\n",
    "                vix.text( '<br/>'.join([''.join(poetry) for poetry in poetries]), win = u'gen_poem'  ) \n",
    "        t.save(model.state_dict(), '{0}_{1}.pth'.format(opt.model_prefix, epoch))\n",
    "    \n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, start_words, ix2word, word2ix, prefix_words=None):\n",
    "    \"\"\"\n",
    "    给定一段词，，根据这几个字接着生成一首完整的诗歌\n",
    "    @model: 模型\n",
    "    @start_words: u'春江潮水连海平'\n",
    "    @return： results list ['春'，'江','潮','水'...] 是一首诗\n",
    "    \"\"\"\n",
    "    # 第一个输入的字，模型输入 input tensor size (seq_len, batch_size)\n",
    "    input = t.Tensor([word2ix['<start>']]).view(1,1).long()\n",
    "    device = t.device('cuda') if opt.use_gpu else t.device('cpu')\n",
    "    input = input.to(device)\n",
    "    \n",
    "    # 暂时不知道这个prefix_words的用法\n",
    "    # 这里应该是为了保留hidden，\n",
    "    if prefix_words:\n",
    "        for word in prefix_words:\n",
    "            output, hidden = model(input, hidden)\n",
    "            input = input.data.new.([word2ix[word]]).view(1,1)\n",
    "            \n",
    "    # 这一段的逻辑是什么？？？ \n",
    "    # 每次取给定的字作为输入，求hidden和output，对于output，每次取概率最大的\n",
    "    results = list(start_words)\n",
    "    start_word_len = len(start_words)\n",
    "    for i in range(opt.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        \n",
    "        if i < start_word_len:\n",
    "            w = results[i]\n",
    "            input = input.data.new.([word2ix[w]]).view(1,1)\n",
    "        else:\n",
    "            # output size 1×vocab_size [[1,2,3,...]]\n",
    "            # 这里应该看一下，输出output是个什么东西\n",
    "            top_index = output.data[0].topk(1)[1][0].item()\n",
    "            w = ix2word(top_index)\n",
    "            results.append(w)\n",
    "            input = input.data.new.([word2ix[w]]).view(1,1)\n",
    "        if w == '<EOP>':\n",
    "            del results[-1]\n",
    "            break\n",
    "            \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(**kwargs):\n",
    "    \"\"\"\n",
    "    等会儿回来补补\n",
    "    \"\"\"\n",
    "    # step： configure\n",
    "    opt._parse(**kwargs)\n",
    "    device = t.device('cuda') if opt.use_gpu else t.device('cpu')\n",
    "    # step: data model\n",
    "    data, word2ix, ix2word = get_data(opt)\n",
    "    model = PoetryModel(len(word2ix), 128, 256)\n",
    "    model.load_state_dict(t.load(opt.model_path,map_location= lambda s_,_:s_))\n",
    "    model.to(device)\n",
    "    # 解码和编码问题应该解决一下了\n",
    "    # python2和python3 字符串兼容\n",
    "    \n",
    "    # step: main\n",
    "    if sys.version_info.major == 3:\n",
    "        if opt.start_words.isprintable():\n",
    "            start_words = opt.start_words\n",
    "            prefix_words = opt.prefix_words if opt.prefix_words else None\n",
    "        else:\n",
    "            start_words = opt.start_words.encode('ascii', 'surrogateescape').decode('utf8')\n",
    "            prefix_words = opt.prefix_words.encode('ascii', 'surrogateescape').decode(\n",
    "                'utf8') if opt.prefix_words else None\n",
    "    else:\n",
    "        start_words = opt.start_words.decode('utf8')\n",
    "        prefix_words = opt.prefix_words.decode('utf8') if opt.prefix_words else None\n",
    "\n",
    "    start_words = start_words.replace(',', u'，').replace('.', u'。').replace('?', u'？')   \n",
    "    \n",
    "    if opt.acrostic:\n",
    "        result = gen_acrostic(model, start_words, ix2word, word2ix, prefix_words)\n",
    "    else:\n",
    "        result = generate(model, start_words, ix2word, word2ix, prefix_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_acrostic(model, start_words, ix2word, word2ix, prefix_words):\n",
    "    \"\"\"\n",
    "    生成藏头诗\n",
    "    @start_words: u'深度学习' 不能为空\n",
    "    @prefix_words: 前缀\n",
    "    @return： results list ['春'，'江','潮','水'...] 是一首诗\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # step: configure\n",
    "    device = t.device('cuda') if opt.use_gpu else t.device('cpu')\n",
    "    \n",
    "    # step: data and model\n",
    "    # 第一个字一定是'<start>'\n",
    "    # 模型输入 input tensor size (seq_len, batch_size)\n",
    "    input = t.Tensor([word2ix['<start>']]).view(1,1).long()\n",
    "    input = input.to(device)\n",
    "    model.to(device)\n",
    "    hidden = None\n",
    "        \n",
    "    # step： 对prefix_words进行输入\n",
    "    prefix_words = '' if prefix_words==None else prefix_words    \n",
    "    for word in prefix_words:\n",
    "        output, hidden = model(input, hidden)\n",
    "        input = input.data.new(word2ix[word]).view(1,1)\n",
    "        \n",
    "    \n",
    "    # step: 对start_words进行输入\n",
    "    # 这里可以看出来，作者假设前面的字只提供hidden的信息，在prefix_words之后，才正式开始作诗\n",
    "    start_words = list(start_words)+[None]\n",
    "    results = []\n",
    "    # 变成列表，方便后续的操作，因为start_words的每个字用过之后就没用了，\n",
    "    # 用pop不行,因为对于空列表会报错,用None作为结尾标志。可以看出，如果我们想让某个序列正常退出，可以通过设置特殊的结尾来实现。\n",
    "    # 这一段的逻辑有点乱，因为prefix_words可能没有，所以对于start_words，必须先进行一个模型生成。\n",
    "    # 对于或有或无的perfix_words，为了消除其存在对代码和思路的影响，应该保证prefix_words前后的代码状态不变，即\n",
    "    \"\"\"\n",
    "    第一种\n",
    "    这种保证了output,hidden的状态不变\n",
    "    output, hidden = model(input, hidden)\n",
    "    \n",
    "    # step： 对prefix_words进行输入\n",
    "    prefix_words = '' if prefix_words==None else prefix_words    \n",
    "    for word in prefix_words:\n",
    "        input = input.data.new(word2ix[word]).view(1,1)\n",
    "        output, hidden = model(input, hidden)\n",
    "        \n",
    "    for i in range(opt.max_gen_len-1):\n",
    "        top_index = output[0].topk(1)[1][0].item()    \n",
    "        ...\n",
    "        output, hidden = model(input, hidden)\n",
    "    \n",
    "    第二种\n",
    "    这种保证了input的状态不变\n",
    "    for word in prefix_words:\n",
    "        output, hidden = model(input, hidden)\n",
    "        input = (input.data.new([word2ix[word]])).view(1, 1)\n",
    "    \n",
    "    for i in range(opt.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        top_index = output.data[0].topk(1)[1][0].item()\n",
    "        \n",
    "        \n",
    "    决定采用第二种，因为代码的主体思路是for i in range(opt.max_gen_len)，prefix_word是插入部分，是可有可无部分。\n",
    "    第一种会造成 top_index与model的切分，不利于后期分析。\n",
    "    或者说，以后碰到这种类型的代码，可以直接跳过中间部分，对后面进行分析。\n",
    "    \n",
    "    \"\"\"\n",
    "    words_pre = {u'。',u'！',u'<start>'}\n",
    "    w = '<start>' # pre_word总是等于当前模型输入的字\n",
    "    \"\"\"\n",
    "    对于w的分析，w在第一次循环时，表示输入的字，\n",
    "    \"\"\"\n",
    "    for i in range(opt.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        top_index = output[0].topk(1)[1][0].item()\n",
    "        \n",
    "        # 当前输入的词input是句号或者感叹号或者<start>,送入藏头诗的字,否则正常输入\n",
    "        # 对w的更新\n",
    "        w = start_words.pop(0) if w in words_set else ix2word(top_index)\n",
    "        \n",
    "        # None表示藏头字都已经取完并且当前字是\n",
    "        if w is None:\n",
    "            break\n",
    "        input = input.data.new(word2ix[w]).view(1,1)\n",
    "        \n",
    "        results.append(w)\n",
    "    \n",
    "    return results\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
